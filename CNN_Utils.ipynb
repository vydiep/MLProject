{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1OtjXuDtGcBqhIp6z5F85PHTlNHVt5oc7",
      "authorship_tag": "ABX9TyPavY/MAEFXl6QeVxTAv/d8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vydiep/MLProject/blob/main/CNN_Utils.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHUYuum1yGD9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "  '''\n",
        "  Read in data from a JSON file\n",
        "\n",
        "  Parameters:\n",
        "    path: The path to the JSON file\n",
        "\n",
        "  Returns:\n",
        "    X: The spectrograms data\n",
        "    y: The labels corresponding to the spectrogram data\n",
        "\n",
        "  '''\n",
        "    with open(path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "        X = np.array(data[\"spectrograms\"])\n",
        "        y = np.array(data[\"labels\"])\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def spect_tensor(path):\n",
        "  '''\n",
        "  Generate mel spectrograms using the JSON data. Convert the spectrograms to \n",
        "  tensors and reshape their dimensions\n",
        "\n",
        "  Parameters:\n",
        "    path: The path to the JSON file\n",
        "\n",
        "  Returns:\n",
        "    spectrograms: A list of spectrogram tensors\n",
        "    y: The composer labels\n",
        "\n",
        "  '''\n",
        "    X, y = load_data(path)\n",
        "\n",
        "    spectrograms = []\n",
        "\n",
        "    for i in X:\n",
        "        spect_tensor = torch.from_numpy(i).unsqueeze(0).repeat(3, 1, 1)\n",
        "        spectrograms.append(spect_tensor)\n",
        "\n",
        "    return spectrograms, y\n",
        "\n",
        "def split_data(path):\n",
        "  '''\n",
        "  Split the data in preparation for training, validation, and testing\n",
        "\n",
        "  Parameters:\n",
        "    path: The path to the JSON file\n",
        "\n",
        "  Returns:\n",
        "    X_train: The spectrograms that will be used for training\n",
        "    X_test: The spectrograms that will be used for testing\n",
        "    X_val: The spectrograms that will be used for validation\n",
        "    y_train: The composer labels for training\n",
        "    y_test: The composer labels for testing\n",
        "    y_val: The composer labels for validation\n",
        "  '''\n",
        "\n",
        "    X, y = spect_tensor(path)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.2, random_state = 42)\n",
        "\n",
        "    return X_train, X_test, X_val, y_train, y_test, y_val\n",
        "\n",
        "def get_loaders(path):\n",
        "  '''\n",
        "  Convert X_train, X_test, X_val, y_train, y_test, and y_val to tensors. Created data set from those tensors, and created data loaders from the data set\n",
        "\n",
        "  Parameters:\n",
        "    path: The path to the JSON file\n",
        "\n",
        "  Returns:\n",
        "    train_loader: An iterator that provides batches of training data\n",
        "    test_loader: An iterator that provides batches of testing data\n",
        "    val_loader: An iterator that provides batches of validation data\n",
        "  '''\n",
        "\n",
        "    X_train, X_test, X_val, y_train, y_test, y_val = split_data(path)\n",
        "\n",
        "    batch_size = 32\n",
        "\n",
        "    X_train_tensor = torch.stack(X_train).to(torch.float32)\n",
        "    X_test_tensor = torch.stack(X_test).to(torch.float32)\n",
        "    X_val_tensor = torch.stack(X_val).to(torch.float32)\n",
        "\n",
        "    y_train_tensor = torch.tensor(y_train).to(torch.float32)\n",
        "    y_test_tensor = torch.tensor(y_test).to(torch.float32)\n",
        "    y_val_tensor = torch.tensor(y_val).to(torch.float32)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)\n",
        "    val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n",
        "\n",
        "    return train_loader, test_loader, val_loader\n",
        "  \n",
        "def train(model, train_loader, val_loader, k_epochs, device):\n",
        "  ''' \n",
        "  Training and validation loop model\n",
        "\n",
        "  Parameters:\n",
        "    model: The model to train\n",
        "    train_loader: An iterator that provides batches of training data\n",
        "    val_loader: An iterator that provides batches of validation data\n",
        "    k_epochs: The number of iterations to train and validate for\n",
        "    device: Specify whether to work on CPU or GPU\n",
        "\n",
        "  Returns:\n",
        "    No returns\n",
        "\n",
        "  Note: \n",
        "    Keeping track of the model's loss and accuracies-- append them to model.history\n",
        "  '''\n",
        "\n",
        "    loss_fn = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    for epoch in range(k_epochs):\n",
        "\n",
        "        print(f'Epoch: {epoch}')\n",
        "\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            X, y = data\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            output = model(X)\n",
        "\n",
        "            loss = loss_fn(output.squeeze(), y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "            \n",
        "            predicted = (output.sigmoid() >= 0.5).float()\n",
        "            predicted = predicted.view(-1)\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y.float()).sum().item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "        train_accuracy = correct / total\n",
        "\n",
        "        model.history[\"train_loss\"].append(train_loss)\n",
        "        model.history[\"train_acc\"].append(train_accuracy)\n",
        "\n",
        "        model.eval()\n",
        "        validation_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, data in enumerate(val_loader, 0):\n",
        "                X, y = data\n",
        "                X = X.to(device)\n",
        "                y = y.to(device)\n",
        "            \n",
        "                output = model(X)\n",
        "\n",
        "                loss = loss_fn(output.squeeze(), y)\n",
        "                validation_loss += loss.item()\n",
        "\n",
        "                predicted = (output.sigmoid() >= 0.5).float()\n",
        "                predicted = predicted.view(-1)\n",
        "                total += y.size(0)\n",
        "                correct += (predicted == y.float()).sum().item()\n",
        "\n",
        "            validation_loss /= len(val_loader)\n",
        "            validation_accuracy = correct / total\n",
        "\n",
        "            model.history[\"val_loss\"].append(validation_loss)\n",
        "            model.history[\"val_acc\"].append(validation_accuracy)\n",
        "\n",
        "            if validation_loss < best_val_loss:\n",
        "                best_val_loss = validation_loss\n",
        "                torch.save(model.state_dict(), '/content/drive/Shareddrives/MLProject/MusicNet/models/cnn-drop-loss.pth')\n",
        "\n",
        "            if validation_accuracy > best_val_acc:\n",
        "                best_val_acc = validation_accuracy\n",
        "                torch.save(model.state_dict(), '/content/drive/Shareddrives/MLProject/MusicNet/models/cnn-drop-acc.pth')\n",
        " \n",
        "        print(f'Train Loss: {train_loss:.4f} Train Accuracy: {train_accuracy:.2f}')\n",
        "        print(f'Validation Loss: {validation_loss:.4f} Validation Accuracy: {validation_accuracy:.2f}')\n",
        "\n",
        "\n",
        "def plot(model, path):\n",
        "  '''\n",
        "  Plot the loss and accuracy history of the model\n",
        "\n",
        "  Parameters:\n",
        "    model: The model to plot\n",
        "    path: The path to save the graphs\n",
        "\n",
        "  Returns:\n",
        "    No returns\n",
        "\n",
        "  Note:\n",
        "    Displays two graphs:\n",
        "      - One of the loss history for training and validation\n",
        "      - One of the validation history for training and validation\n",
        "\n",
        "  \n",
        "\n",
        "  '''\n",
        "    plt.figure(figsize=(16, 5))\n",
        "\n",
        "    # Plot loss history\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(model.history[\"train_loss\"], label='Train Loss')\n",
        "    plt.plot(model.history[\"val_loss\"], label='Validation Loss')\n",
        "    plt.title('Loss History')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy history\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(model.history[\"train_acc\"], label='Train Accuracy')\n",
        "    plt.plot(model.history[\"val_acc\"], label='Validation Accuracy')\n",
        "    plt.title('Accuracy History')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.suptitle('Loss and Accuracy Histories for CNN Model With Dropout Layer')\n",
        "    plt.savefig(path)\n",
        "    plt.show()\n",
        "\n",
        "def test(model, test_loader, device):\n",
        "  '''\n",
        "  Testing loop for the model\n",
        "\n",
        "  Parameters:\n",
        "    model: The model to train\n",
        "    test_loader: An iterator that provides batches of testing data\n",
        "    device: Specify whether to work on CPU or GPU\n",
        "  '''\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # torch.no_grad creates an environment in which we do NOT store the \n",
        "    # computational graph. We don't need to do this because we don't care about \n",
        "    # gradients unless we're training\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            X, y = data\n",
        "            X = X.to(device)\n",
        "            y = y.to(device)\n",
        "            \n",
        "            # run all the images through the model\n",
        "            y_hat = model(X)\n",
        "\n",
        "            # the class with the largest model output is the prediction\n",
        "            pred = (y_hat.sigmoid() >= 0.5).float()\n",
        "            pred = pred.view(-1)\n",
        "\n",
        "            # compute the accuracy\n",
        "            total += y.size(0)\n",
        "            correct += (pred == y).sum().item()\n",
        "\n",
        "    print(f'Test accuracy: {100 * correct // total}%')"
      ],
      "metadata": {
        "id": "bEO3iuEayL9k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}